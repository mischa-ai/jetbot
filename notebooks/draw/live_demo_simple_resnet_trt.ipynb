{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Draw! - Live Demo simple version (with TensorRT)\n",
    "\n",
    "The task of the robot is to drive around without collision to draw on a canvas.\n",
    "\n",
    "The trained network should estimate in which direction it is save to drive:\n",
    "\n",
    "- forward : both tracks have same speed value\n",
    "- right : left track has set speed, right track is set 0\n",
    "- left : right track has set speed, left track is set 0\n",
    "- turn_right : left track has set speed, right has set -speed\n",
    "- turn_left : right track has set speed, left has set -speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn.functional as F\n",
    "import cv2\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "import traitlets\n",
    "from jetbot import Robot, Camera\n",
    "from torch2trt import TRTModule\n",
    "import time\n",
    "\n",
    "device = torch.device('cuda')\n",
    "\n",
    "model_trt = TRTModule()\n",
    "model_trt.load_state_dict(torch.load('best_model_trt.pth'))\n",
    "\n",
    "mean = torch.Tensor([0.485, 0.456, 0.406]).cuda().half()\n",
    "std = torch.Tensor([0.229, 0.224, 0.225]).cuda().half()\n",
    "\n",
    "def preprocess(image):\n",
    "    image = PIL.Image.fromarray(image)\n",
    "    image = transforms.functional.to_tensor(image).to(device).half()\n",
    "    image.sub_(mean[:, None, None]).div_(std[:, None, None])\n",
    "    return image[None, ...]\n",
    "\n",
    "camera = Camera.instance(width=224, height=224, fps=15)\n",
    "\n",
    "robot = Robot()\n",
    "\n",
    "class_names = ['forward', 'left', 'right', 'turn_left', 'turn_right']\n",
    "\n",
    "def move_robot(direction, speed):\n",
    "    if direction == 'forward':\n",
    "        robot.set_motors(speed, speed)\n",
    "    elif direction == 'left':\n",
    "        robot.set_motors(0, speed)\n",
    "    elif direction == 'right':\n",
    "        robot.set_motors(speed, 0)\n",
    "    elif direction == 'turn_left':\n",
    "        robot.set_motors(-speed, speed)\n",
    "    elif direction == 'turn_right':\n",
    "        robot.set_motors(speed, -speed)\n",
    "    else:\n",
    "        robot.stop()\n",
    "\n",
    "def update(change):\n",
    "    x = change['new']\n",
    "    x = preprocess(x)\n",
    "    y = model_trt(x)\n",
    "    y = F.softmax(y, dim=1)\n",
    "\n",
    "    pred_class = torch.argmax(y, dim=1).item()\n",
    "    pred_prob = torch.max(y).item()\n",
    "\n",
    "    speed = 1\n",
    "    threshold = 0.35\n",
    "\n",
    "    if pred_prob > threshold:\n",
    "        move_robot(class_names[pred_class], speed)\n",
    "    else:\n",
    "        move_robot('stop', 0)\n",
    "\n",
    "update({'new': camera.value})  # call the update function once to initialize\n",
    "camera.observe(update, names='value')  # update function is called asynchronously"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stop the robot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "camera.unobserve_all()\n",
    "camera.stop()\n",
    "time.sleep(1)\n",
    "robot.stop()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
